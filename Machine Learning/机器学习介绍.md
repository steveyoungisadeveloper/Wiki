[TOC]


# 机器学习介绍
机器学习的目的是通过算法来进一步了解数据中隐藏的规律 **有监督学习**主要用于执行分类和回归 **无监督学习**主要用来执行聚类和密度估计
## 监督学习 Supervised Learning
提供给计算机一些数据和这些数据对应的值，例如哪些是猫哪些是狗 让计算机学习哪些标签可以代表哪些图片 可以用来预测房屋价格 股票涨停 
### “分类” 的主要方法 - KSLAND
#### K近邻

==近朱者赤近墨者黑==

k 近邻算法假设给定一个训练数据集，其中的实例类别已定。分类时，对新的实例，根据其 k 个最近邻的训练实例的类别，通过多数表决等方式进行预测。

通俗讲，K近邻是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的 k 个实例，这 k 个实例的多数属于某个类，就把该输入实例分为这个类。  

K近邻的输入是实例的特征向量，输出为实例类别

##### 案例

> 电影可以按照题材分类，那么如何区分 `动作片` 和 `爱情片` 呢？
>
> 1. 动作片：打斗次数更多
> 2. 爱情片：亲吻次数更多
>
> 基于电影中的亲吻、打斗出现的次数，使用 k-近邻算法构造程序，就可以自动划分电影的题材类型。
>
> ![电影视频案例](https://github.com/apachecn/MachineLearning/raw/master/images/2.KNN/knn-1-movie.png)
>
> 现在根据上面我们得到的样本集中所有电影与未知电影的距离，按照距离递增排序，可以找到 k 个距离最近的电影。
> 假定 k=3，则三个最靠近的电影依次是， He's Not Really into Dudes 、 Beautiful Woman 和 California Man。
> knn 算法按照距离最近的三部电影的类型，决定未知电影的类型，而这三部电影全是爱情片，因此我们判定未知电影是爱情片。

##### 优缺点

优点：精度高、对异常值不敏感、无数据输入假定
缺点：计算复杂度高、空间复杂度高

#### 支持向量机
#### 逻辑回归
#### adaboost
#### 朴素贝叶斯
#### 决策树

### “回归” 的主要方法
#### 线性回归
#### 非线性回归
#### 岭回归

### 神经网络是一种监督学习方式
人工神经网络已成体系 所有人工神经元都是不可更换的 in other word 没有凭空产生新连接这回事
#### 学习方法 
我已知结果 不过我想让神经网络帮我完成这个事情 我们需要准备非常多的学习数据 然后将这套数据一次次放入系统中 数据信号会一次次的传递到结果 然后通过确定结果是不是我们想要的来修改神经网络当中神经元的强度 这种修改被称为**误差反向传递** 这种传递可以认为是将得到的结果反馈给神经元来确认它对正确结果产生有没有贡献 争取下次做出更好的贡献
人工神经网络靠的是正向和反向传播来更新神经元从而形成一个更好的传播系统 是一个能让计算机处理和优化的神经模型

## 无监督学习 Unsupervised Learning
提供给计算机无标签的数据 例如只提供猫狗图片 不提供名称 让计算机自己判断分类 总结出两种图片不同之处 计算机观察各种数据间的特性 发现特性背后的规律
### K均值聚类
### fp growth

## 半监督学习 Semi-supervised Learning
利用少量有标签的样本和大量没有标签的样本进行分类和训练

## 强化学习 Reinforcement Learning
把计算机丢到一个完全陌生的环境让他完成一项从未接触过的任务 计算机会自己尝试各种手段去适应陌生环境 学会完成任务的方法或途径 
例如机器人投篮 投进积一分 他会自己尝试各种投篮方法 这样开始命中率很低 但是计算机会自己总结失败或者成功经验以提高命中率 例如 AlphaGO

## 遗传算法 Genetic Algorithm
模拟进化理论 淘汰弱者 适者生存 通过淘汰机制选择最优的设计模型
例如让计算机学会玩马里奥 第一代马里奥不就就会牺牲 计算机会基于一代马里奥随机生成二代马里奥 然后保存最厉害的二代马里奥去生成第三代并循环下去 基于强者繁衍和变异理论
